{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miniproyecto 1 (Actividad 3)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Integrantes:\n",
    "<i> - Hugo Torricos\n",
    "<br><i> - Alejandro Tolosa\n",
    "<br><i> - Isabel Catalán\n",
    "<br><i> - Anderson Suárez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Transformación e imputación de datos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrir entorno de programación, de preferencia utilizar Visual studio code. Importe las librerías pandas, searborn, matplotlib, numpy y sklearn. Le recomendamos usar un ambiente de conda específico para el curso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar la base de datos (Gaia NaN.csv o metadato.csv ). Cree una función que permita cargar la base de datos bajo diferentes condiciones. Los argumentos de esta función deben ser: (i) un string con el nombre del directorio donde se encuetre la base de datos, (ii) una variable booleana que indique si se trabajará con una muestra o con la base de datos completa y (iii) un argumento que reciba las columnas con las que se pueda trabajar en una lista. Usted puede agregar nuevos argumentos que den mayor flexibilidad a la carga de datos. Recuerde verificar el tipo de variable reconocido por pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(folder:str, sample=False, useColumns=[], samplesize=-1):\n",
    "\n",
    "    df = pd.read_csv(folder)\n",
    "    if sample:\n",
    "        df = df.loc[0:samplesize-1]\n",
    "    for c in df.columns:\n",
    "        if c not in useColumns:\n",
    "            df = df.drop(c, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genere un diagnóstico de estadística descriptiva y de datos faltantes. Cree una función que permita realizar el diagnóstico de forma flexible, la función debe retornar, media, desviación estándar, valores perdidos por descriptor, valor máximo y valor mínimo. Usted puede usar funciones internas de otras librerías. Cada uno de los estadísticos debe ser un argumento booleano en la función y solo cuando se indique True este se calculará. Los descriptores para los cuales se calcular´an estos descriptores también deben ser un argumento de la función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnosis(db, mean=True, stdDev=True, lostValues=True, maxVal=True, minVal=True, descriptors=[]):\n",
    "    if mean:\n",
    "        for d in descriptors:\n",
    "            print(f\"{d} mean: {db[d].mean()}\")\n",
    "    if stdDev:\n",
    "        for d in descriptors:\n",
    "            print(f\"{d} standard deviation: {db[d].std()}\")\n",
    "    if lostValues:\n",
    "        for d in descriptors:\n",
    "            print(f\"{d} na count: {len(db)-db[d].count()}\")\n",
    "    if maxVal:\n",
    "        for d in descriptors:\n",
    "            print(f\"{d} max: {db[d].max()}\")\n",
    "    if minVal:\n",
    "        for d in descriptors:\n",
    "            print(f\"{d} min: {db[d].min()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute los datos perdidos con el método de su elección. Genere una función que reciba una lista de descriptores, el dataframe original y una lista con las estrategias de imputación de cada descriptor. La función debe retornar la nueva base de datos imputada. ¿Cómo cambió la distribución de los datos con la imputación realizada?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillMissing(db, descriptors=[], strats=[]):\n",
    "    for i in range(descriptors):\n",
    "        if strats[i].split[0]=='fill':\n",
    "            if strats[i].split[1] == 'True':\n",
    "                db[descriptors[i]] = db[descriptors[i]].fillna(True)\n",
    "            elif strats[i].split[1] == 'False':\n",
    "                db[descriptors[i]] = db[descriptors[i]].fillna(False)\n",
    "            elif strats[i].split[1].replace('.','',1).isdigit():\n",
    "                db[descriptors[i]] = db[descriptors[i]].fillna(float(strats[i].split[1]))\n",
    "            else:\n",
    "                db[descriptors[i]] = db[descriptors[i]].fillna(strats[i].split[1])\n",
    "        elif strats[i].split[0]=='ffill':\n",
    "            db[descriptors[i]] = db[descriptors[i]].ffill()\n",
    "        elif strats[i].split[0]=='bfill':\n",
    "            db[descriptors[i]] = db[descriptors[i]].bfill()\n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genera 2 gráficos diferentes (ejemplo: boxplot, scatter plot, histogramas, gráfico de torta, etc.) que entreguen información relevante para el modelamiento del problema (ejemplo: correlaciones evidentes, datos at´ıpicos, patrones no lineales de relaciones, etc). Debe explicar tanto la elecci´on de cada gráfico como la información otenida a partir de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cree una función que permita hacer scatter plots y/o box plots para dos descriptores datos. La función debe recibir como argumento las dos variables, y el tipo de gráfico que se desea obtener. La función debe recibir como argumento la decisión de visualizar o guardar los gráficos realizados. Usted puede agregar más argumentos para obtener visualizaciones más personalizadas. Usando dicha función, genere visualizaciones para 5 de los descriptores de la base de datos entregada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph(db, xVar, yVar, graphType, save = False):\n",
    "    plt.figure(figsize=[])\n",
    "    plt.title(graphType)\n",
    "    \n",
    "    if graphType == \"scatter\":\n",
    "        plt.xlabel(xVar)\n",
    "        plt.ylabel(yVar)\n",
    "        plt.scatter(db[xVar], db[yVar], c='#008080', alpha=0.5)\n",
    "    elif graphType == \"boxplot\":\n",
    "        plt.xlabel(\"Categorías\")\n",
    "        plt.ylabel(\"Valores\")\n",
    "        plt.boxplot(db[xVar], db[yVar], vert=True, patch_artist=True)\n",
    "        plt.xticks([1, 2], [xVar, yVar])\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(\"imagen1.jpg\")\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplique normalización z o escalamiento a los datos. Genere una función que permita aplicar estas transformaciones a los datos, como argumento se debe indicar qué tipo de estrategia se usará para cada descriptor. La función debe retornar el dataframe modificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processDescriptors(db, strats=[]):\n",
    "    for s in strats:\n",
    "        if s.split()[1] == 'zscore':\n",
    "            db[s.split()[0]].apply(zscore)\n",
    "        elif s.split()[1] == 'escalamiento':\n",
    "            scaler = MinMaxScaler()\n",
    "            db[s.split()[0]] = scaler.fit(db[[s.split()[0]]])\n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genere sets de entrenamiento y testeo, con separación estratificada. Genere una función que aplique este procesamiento. No olvide fijar la semilla aleatoria para poder replicar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndTestSets(db):\n",
    "    X = db.loc[:, :-1]\n",
    "    y = db.loc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=10, stratify=StratifiedKFold)\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consolide todas las funciones en una clase. Esta clase tendrá por nombre preprocesamiento. Algunos de los parámetros que se usan en las funciones antes creadas pueden ser entregadas en la inicialización de la clase. Agregue una función que aplique todo el procesamiento, denomine a esta función ejecutar procesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocesamiento():\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def loadData(self, folder:str, sample=False, useColumns=[], samplesize=-1):\n",
    "        df = pd.read_csv(folder)\n",
    "        if sample:\n",
    "            df = df.loc[0:samplesize-1]\n",
    "        for c in df.columns:\n",
    "            if c not in useColumns:\n",
    "                df = df.drop(c, axis=1)\n",
    "        return df\n",
    "\n",
    "    def diagnosis(self, db, mean=True, stdDev=True, lostValues=True, maxVal=True, minVal=True, descriptors=[]):\n",
    "        if mean:\n",
    "            for d in descriptors:\n",
    "                print(f\"{d} mean: {db[d].mean()}\")\n",
    "        if stdDev:\n",
    "            for d in descriptors:\n",
    "                print(f\"{d} standard deviation: {db[d].std()}\")\n",
    "        if lostValues:\n",
    "            for d in descriptors:\n",
    "                print(f\"{d} na count: {len(db)-db[d].count()}\")\n",
    "        if maxVal:\n",
    "            for d in descriptors:\n",
    "                print(f\"{d} max: {db[d].max()}\")\n",
    "        if minVal:\n",
    "            for d in descriptors:\n",
    "                print(f\"{d} min: {db[d].min()}\")\n",
    "        \n",
    "\n",
    "    def fillMissing(self, db, descriptors=[], strats=[]):\n",
    "        for i in range(descriptors):\n",
    "            if strats[i].split[0]=='fill':\n",
    "                if strats[i].split[1] == 'True':\n",
    "                    db[descriptors[i]] = db[descriptors[i]].fillna(True)\n",
    "                elif strats[i].split[1] == 'False':\n",
    "                    db[descriptors[i]] = db[descriptors[i]].fillna(False)\n",
    "                elif strats[i].split[1].replace('.','',1).isdigit():\n",
    "                    db[descriptors[i]] = db[descriptors[i]].fillna(float(strats[i].split[1]))\n",
    "                else:\n",
    "                    db[descriptors[i]] = db[descriptors[i]].fillna(strats[i].split[1])\n",
    "            elif strats[i].split[0]=='ffill':\n",
    "                db[descriptors[i]] = db[descriptors[i]].ffill()\n",
    "            elif strats[i].split[0]=='bfill':\n",
    "                db[descriptors[i]] = db[descriptors[i]].bfill()\n",
    "        return db\n",
    "\n",
    "    def graph(self, db, xVar, yVar, graphType, save = False):\n",
    "        plt.figure(figsize=[])\n",
    "        if graphType == \"scatter\":\n",
    "            plt.title(\"\")\n",
    "            plt.xlabel(xVar)\n",
    "            plt.ylabel(yVar)\n",
    "            plt.scatter(db[xVar], db[yVar], c='#008080', alpha=0.5)\n",
    "        elif graphType == \"boxplot\":\n",
    "            plt.title(\"\")\n",
    "            plt.xlabel(\"Categorías\")\n",
    "            plt.ylabel(\"Valores\")\n",
    "            plt.boxplot(db[xVar], db[yVar], vert=True, patch_artist=True)\n",
    "            plt.xticks([1, 2], [xVar, yVar])\n",
    "        if save:\n",
    "            plt.savefig(\"imagen1.jpg\")\n",
    "        else:\n",
    "            plt.show()\n",
    "        \n",
    "    def processDescriptors(self, db, strats=[]):\n",
    "        for s in strats:\n",
    "            if s.split()[1] == 'zscore':\n",
    "                db[s.split()[0]].apply(zscore)\n",
    "            elif s.split()[1] == 'escalamiento':\n",
    "                scaler = MinMaxScaler()\n",
    "                db[s.split()[0]] = scaler.fit(db[[s.split()[0]]])\n",
    "        return db\n",
    "    \n",
    "    def trainAndTestSets(self, db):\n",
    "        X = db.loc[:, :-1]\n",
    "        y = db.loc[:, -1]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=10, stratify=StratifiedKFold)\n",
    "        return (X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    def ejecutar_procesamiento(self, prep, file):\n",
    "\n",
    "        data = prep.loadData(file)\n",
    "        prep.diagnosis(data, descriptors=['age'])\n",
    "        data = prep.fillMissing(data, descriptors=['smoke'], strats=['fill False'])\n",
    "        prep.graph()\n",
    "        prep.graph()\n",
    "        prep.processDescriptors()\n",
    "        prep.data = data\n",
    "        return prep.trainAndTestSets(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = 'data\\measurements.csv'\n",
    "prep = preprocesamiento(ruta)\n",
    "\n",
    "prep.ejecutar_procesamiento(prep, ruta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Entrenamiento de modelos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajuste los clasificadores naive Bayes (desde sklearn.naive bayes.GaussianNB) y regresión logística (desde sklearn.linear model.LogisticRegression ). Genere una función con nombre clasificador que reciba como argumento: (i) el tipo de clasificador que desea ajustar, (ii) el nombre de la dirección donde se guardara el modelo y (iii) los datos de entrenamiento. La función solo debe ajustar y guardar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cree una función que tenga por nombre evaluar rendimiento, esta función debe recibir la direcci´on del modelo, los datos que desea evaluar (entrenamiento o test) y el tipo de análisis. Los análisis posibles son: (i) mostrar la matriz de confusión y (ii) mostrar las métricas de evaluación (accuracy, recall, precision y F1-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use estas funciones para probar distintos modelos, explore los siguientes argumentos en la regresión logística: penalty, C, class weight, l1 ratio. En naive Bayes modifique: priors de acuerdo a la descripción de la librería. Entregue un análisis de los resultados y seleccione un modelo. También puede aplicar procedimientos para seleccionar los descriptores que se incluyen en el modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Modelos basados en árboles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Explore la documentación del modelo clasificador árbol de decisión link. Describa el aprendizaje de este modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Ajuste un árbol de decisión a los datos usados en las secciones anteriores y compare su rendimiento con respecto a los modelos naive Bayes y la regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Repita a y b pero con el clasificador random forest link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformación e Imputación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejecutar_procesamiento(prep, file):\n",
    "\n",
    "    data = prep.loadData(file)\n",
    "\n",
    "    prep.diagnosis(data, descriptors=['age'])\n",
    "\n",
    "    data = prep.fillMissing(data, descriptors=['smoke'], strats=['fill False'])\n",
    "\n",
    "    prep.graph()\n",
    "\n",
    "    prep.graph()\n",
    "\n",
    "    prep.processDescriptors()\n",
    "\n",
    "    prep.data = data\n",
    "\n",
    "    return prep.trainAndTestSets(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = 'data\\measurements.csv'\n",
    "prep = preprocesamiento([])\n",
    "ejecutar_procesamiento(prep, ruta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificador(type, saveTo, trainingData):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_rendimiento(folder:str, data, analysisType):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entornoConda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
