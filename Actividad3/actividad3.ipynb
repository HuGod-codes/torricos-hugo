{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miniproyecto 1 (Actividad 3)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Integrantes:\n",
    "<i> - Hugo Torricos\n",
    "<br><i> - Alejandro Tolosa\n",
    "<br><i> - Isabel Catalán\n",
    "<br><i> - Anderson Suárez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Transformación e imputación de datos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrir entorno de programación, de preferencia utilizar Visual studio code. Importe las librerías pandas, searborn, matplotlib, numpy y sklearn. Le recomendamos usar un ambiente de conda específico para el curso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genera 2 gráficos diferentes (ejemplo: boxplot, scatter plot, histogramas, gráfico de torta, etc.) que entreguen información relevante para el modelamiento del problema (ejemplo: correlaciones evidentes, datos at´ıpicos, patrones no lineales de relaciones, etc). Debe explicar tanto la elección de cada gráfico como la información otenida a partir de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cree una función que permita hacer scatter plots y/o box plots para dos descriptores datos. La función debe recibir como argumento las dos variables, y el tipo de gráfico que se desea obtener. La función debe recibir como argumento la decisión de visualizar o guardar los gráficos realizados. Usted puede agregar más argumentos para obtener visualizaciones más personalizadas. Usando dicha función, genere visualizaciones para 5 de los descriptores de la base de datos entregada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplique normalización z o escalamiento a los datos. Genere una función que permita aplicar estas transformaciones a los datos, como argumento se debe indicar qué tipo de estrategia se usará para cada descriptor. La función debe retornar el dataframe modificado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genere sets de entrenamiento y testeo, con separación estratificada. Genere una función que aplique este procesamiento. No olvide fijar la semilla aleatoria para poder replicar los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consolide todas las funciones en una clase. Esta clase tendrá por nombre preprocesamiento. Algunos de los parámetros que se usan en las funciones antes creadas pueden ser entregadas en la inicialización de la clase. Agregue una funci´on que aplique todo el procesamiento, denomine a esta función ejecutar procesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocesamiento():\n",
    "    def __init__(self, file:str):\n",
    "        self.file = file\n",
    "        self.data = pd.DataFrame()\n",
    "\n",
    "    def load_config(self, config_path='config.yaml'):\n",
    "        with open(config_path, 'r') as file:\n",
    "            self.config = yaml.safe_load(file)\n",
    "\n",
    "        self.columnas_usar = self.config['preprocesamiento']['columnas_usar']\n",
    "        self.muestra = self.config['preprocesamiento']['muestra']\n",
    "        self.estrategias_imputacion = self.config['preprocesamiento']['estrategias_imputacion']\n",
    "        self.sample_size = self.config['preprocesamiento']['sample_size']\n",
    "        self.seed = self.config['preprocesamiento']['seed']\n",
    "\n",
    "        self.test_size = self.config['modelos']['entrenamiento']['test_size']\n",
    "        self.random_state = self.config['modelos']['entrenamiento']['random_state']\n",
    "        self.stratify = self.config['modelos']['entrenamiento']['stratify']\n",
    "        self.clasificador_tipo = self.config['modelos']['clasificador']['tipo']\n",
    "        self.model_path = self.config['modelos']['clasificador']['ruta_guardado']\n",
    "\n",
    "\n",
    "    def loadData(self, sample=False, useColumns=[], samplesize=-1):\n",
    "\n",
    "        df = pd.read_csv(self.file)\n",
    "        if sample:\n",
    "            df = df.loc[0:samplesize-1]\n",
    "        for c in df.columns:\n",
    "            if c not in useColumns:\n",
    "                df = df.drop(c, axis=1)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def diagnosis(self, db, mean=True, stdDev=True, lostValues=True, maxVal=True, minVal=True, descriptors=[]):\n",
    "        if mean:\n",
    "            for d in descriptors:\n",
    "                print(f\"{d} mean: {db[d].mean()}\")\n",
    "        if stdDev:\n",
    "            for d in descriptors:\n",
    "                print(f\"{d} standard deviation: {db[d].std()}\")\n",
    "        if lostValues:\n",
    "            for d in descriptors:\n",
    "                print(f\"{d} na count: {len(db)-db[d].count()}\")\n",
    "        if maxVal:\n",
    "            for d in descriptors:\n",
    "                print(f\"{d} max: {db[d].max()}\")\n",
    "        if minVal:\n",
    "            for d in descriptors:\n",
    "                print(f\"{d} min: {db[d].min()}\")\n",
    "        \n",
    "\n",
    "    def fillMissing(self, db, descriptors=[], strats=[]):\n",
    "        for i in range(descriptors):\n",
    "            if strats[i].split[0]=='fill':\n",
    "                if strats[i].split[1] == 'True':\n",
    "                    db[descriptors[i]] = db[descriptors[i]].fillna(True)\n",
    "                elif strats[i].split[1] == 'False':\n",
    "                    db[descriptors[i]] = db[descriptors[i]].fillna(False)\n",
    "                elif strats[i].split[1].replace('.','',1).isdigit():\n",
    "                    db[descriptors[i]] = db[descriptors[i]].fillna(float(strats[i].split[1]))\n",
    "                else:\n",
    "                    db[descriptors[i]] = db[descriptors[i]].fillna(strats[i].split[1])\n",
    "            elif strats[i].split[0]=='ffill':\n",
    "                db[descriptors[i]] = db[descriptors[i]].ffill()\n",
    "            elif strats[i].split[0]=='bfill':\n",
    "                db[descriptors[i]] = db[descriptors[i]].bfill()\n",
    "        return db\n",
    "\n",
    "    def graph(self, db, xVar, yVar, graphType, save = False):\n",
    "        plt.figure(figsize=[])\n",
    "        if graphType == \"scatter\":\n",
    "            plt.title(\"\")\n",
    "            plt.xlabel(xVar)\n",
    "            plt.ylabel(yVar)\n",
    "            plt.scatter(db[xVar], db[yVar], c='#008080', alpha=0.5)\n",
    "        elif graphType == \"boxplot\":\n",
    "            sns.boxplot(x='diagnostic', y='age', data=self.data)\n",
    "            plt.title('Boxplot de Edad por Diagnóstico')\n",
    "            plt.xlabel('Diagnóstico')\n",
    "            plt.ylabel('Edad')\n",
    "            plt.show()\n",
    "        \n",
    "        if save:\n",
    "            plt.savefig(\"imagen1.jpg\")\n",
    "        else:\n",
    "            plt.show()\n",
    "        \n",
    "\n",
    "    def processDescriptors(self, db, strats=[]):\n",
    "\n",
    "        for s in strats:\n",
    "            if s.split()[1] == 'zscore':\n",
    "                db[s.split()[0]].apply(zscore)\n",
    "            elif s.split()[1] == 'escalamiento':\n",
    "                scaler = MinMaxScaler()\n",
    "                db[s.split()[0]] = scaler.fit(db[[s.split()[0]]])\n",
    "        return db\n",
    "    \n",
    "    def trainAndTestSets(self, db):\n",
    "        X = db.loc[:, :-1]\n",
    "        y = db.loc[:, -1]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=10, stratify=StratifiedKFold)\n",
    "\n",
    "        return (X_train, X_test, y_train, y_test)   \n",
    "                \n",
    "    def ejecutar_procesamiento(self, file):\n",
    "\n",
    "        self.data = self.loadData(file, samplesize=2000, useColumns=['patient_id','smoke','drink', 'age','fitspatrick','region','diagnosis','itch','grew','hurt','changed','bleed', 'diameter_1'])\n",
    "        self.diagnosis(self.data, descriptors=['age', 'fitspatrick'])\n",
    "        self.data = self.fillMissing(self.data, descriptors=['smoke','drink'], strats=['fill False','fill False'])\n",
    "        self.graph(xVar='age', yVar='fitspatrick', graphType='scatter')\n",
    "\n",
    "        mapping = {'NEV': 3, 'BCC': 4, 'ACK': 2, 'SEK': 1, 'MEL': 6, 'SCC': 5}\n",
    "        self.data['diagnosis'] = self.data['diagnosis'].map(mapping)\n",
    "\n",
    "        self.graph(xVar='age', yVar='diagnosis', graphType='scatter')\n",
    "        self.processDescriptors(self.data, strats=[])\n",
    "        return self.trainAndTestSets(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age mean: 60.2175\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'fitzpatrick'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\aleja\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'fitzpatrick'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m ruta \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadatos.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m prep \u001b[38;5;241m=\u001b[39m preprocesamiento(ruta)\n\u001b[1;32m----> 4\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mprep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mejecutar_procesamiento\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruta\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[31], line 110\u001b[0m, in \u001b[0;36mpreprocesamiento.ejecutar_procesamiento\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mejecutar_procesamiento\u001b[39m(\u001b[38;5;28mself\u001b[39m, file):\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloadData(file, samplesize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m, useColumns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatient_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmoke\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrink\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfitzpatrick\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregion\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiagnosis\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitch\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrew\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhurt\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchanged\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbleed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiameter_1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiagnosis\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescriptors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfitzpatrick\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfillMissing(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, descriptors\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmoke\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrink\u001b[39m\u001b[38;5;124m'\u001b[39m], strats\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfill False\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfill False\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph(xVar\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m, yVar\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfitzpatrick\u001b[39m\u001b[38;5;124m'\u001b[39m, graphType\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscatter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[31], line 37\u001b[0m, in \u001b[0;36mpreprocesamiento.diagnosis\u001b[1;34m(self, db, mean, stdDev, lostValues, maxVal, minVal, descriptors)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mean:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m descriptors:\n\u001b[1;32m---> 37\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00md\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m mean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdb\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stdDev:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m descriptors:\n",
      "File \u001b[1;32mc:\\Users\\aleja\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\aleja\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'fitzpatrick'"
     ]
    }
   ],
   "source": [
    "ruta = 'metadatos.csv'\n",
    "prep = preprocesamiento(ruta)\n",
    "\n",
    "X_train, X_test, y_train, y_test = prep.ejecutar_procesamiento(ruta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Elegimos la gráfica BOXPLOT para las variables “DIAGNOSTIC” y “AGES” porque nos permite visualizar la mediana, los cuartiles y valores atípicos, de manera que nos permite comparar fácilmente entre las diferentes categorías de diagnóstico. \n",
    "De la gráfica realizada podemos concluir que, la edad mediana en la que se recibió un diagnóstico de NEV es 35 años, de BCC es 63 años, de ACK es 62 años, de SEK es 67 años, de SCC es 69 años y de MEL es 58 años.\n",
    "Notemos que, usualmente este tipo de diagnósticos se producen luego de los 50 años, sin embargo, el diagnóstico NEV se produce usualmente antes de los 50 años.\n",
    "Claramente, el diagnostico Nevus o lunares (NEV) es más usual entre los jóvenes, a diferencia de las enfermedades de la Base de Datos. Se presentan casos desde la infancia y el primer cuartil contiene casos desde los 24 años."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Entrenamiento de modelos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajuste los clasificadores naive Bayes (desde sklearn.naive bayes.GaussianNB) y regresi´on logística (desde sklearn.linear model.LogisticRegression ). Genere una función con nombre clasificador que reciba como argumento: (i) el tipo de clasificador que desea ajustar, (ii) el nombre de la dirección donde se guardara el modelo y (iii) los datos de entrenamiento. La función solo debe ajustar y guardar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificador(type, saveTo:str, xTrain, yTrain, model):\n",
    "    \n",
    "    if type == 'Naive_Bayes':\n",
    "        # Gaussian NB\n",
    "        model.fit(xTrain, yTrain)\n",
    "    elif type == 'regresion Log':\n",
    "        # Regresion logistica\n",
    "        model.fit(xTrain,yTrain)\n",
    "\n",
    "    pickle.dump(model, open(saveTo, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cree una función que tenga por nombre evaluar rendimiento, esta función debe recibir la direcci´on del modelo, los datos que desea evaluar (entrenamiento o test) y el tipo de análisis. Los análisis posibles son: (i) mostrar la matriz de confusión y (ii) mostrar las métricas de evaluación (accuracy, recall, precision y F1-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_rendimiento(file:str, xTest, yTest, analysisType:str):\n",
    "    model = pickle.load(open(file, \"rb\"))\n",
    "    yPredicted = model.predict(xTest.reshape(-1,1))\n",
    "\n",
    "    if analysisType == 'confusion matrix':\n",
    "        print(confusion_matrix(yTest, yPredicted))\n",
    "    elif analysisType == 'metrics':\n",
    "        print(recall_score(yTest, yPredicted))\n",
    "        print(accuracy_score(yTest, yPredicted))\n",
    "        print(precision_score(yTest, yPredicted))\n",
    "        print(f1_score(yTest, yPredicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use estas funciones para probar distintos modelos, explore los siguientes argumentos en la regresión logística: penalty, C, class weight, l1 ratio. En naive Bayes modifique: priors de acuerdo a la descripción de la librería. Entregue un análisis de los resultados y seleccione un modelo. También puede aplicar procedimientos para seleccionar los descriptores que se incluyen en el modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = GaussianNB()\n",
    "clasificador(\"Naive_Bayes\", \"clf1.plk\", X_train, y_train, clf1)\n",
    "evaluar_rendimiento(\"clf1.plk\", X_test, y_test, \"confusion matrix\")\n",
    "evaluar_rendimiento(\"clf1.plk\", X_test, y_test, \"metrics\")\n",
    "\n",
    "logr1 = LogisticRegression()\n",
    "clasificador(\"regression Log\", \"logr1.plk\", X_train, y_train, logr1)\n",
    "evaluar_rendimiento(\"logr1.plk\", X_test, y_test, \"confusion matrix\")\n",
    "evaluar_rendimiento(\"logr1.plk\", X_test, y_test, \"metrics\")\n",
    "\n",
    "logr2 = LogisticRegression(penalty='l2', c=2.0, class_weight='balanced')\n",
    "clasificador(\"regression Log\", \"logr2.plk\", X_train, y_train, logr2)\n",
    "evaluar_rendimiento(\"logr2.plk\", X_test, y_test, \"confusion matrix\")\n",
    "evaluar_rendimiento(\"logr2.plk\", X_test, y_test, \"metrics\")\n",
    "\n",
    "logr3 = LogisticRegression(penalty='l1', c=2.0, class_weight='balanced')\n",
    "clasificador(\"regression Log\", \"logr3.plk\", X_train, y_train, logr3)\n",
    "evaluar_rendimiento(\"logr3.plk\", X_test, y_test, \"confusion matrix\")\n",
    "evaluar_rendimiento(\"logr3.plk\", X_test, y_test, \"metrics\")\n",
    "\n",
    "logr4 = LogisticRegression(l1_ratio=0.3, c=2.0, class_weight='balanced')\n",
    "clasificador(\"regression Log\", \"logr4.plk\", X_train, y_train, logr4)\n",
    "evaluar_rendimiento(\"logr4.plk\", X_test, y_test, \"confusion matrix\")\n",
    "evaluar_rendimiento(\"logr4.plk\", X_test, y_test, \"metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genere un diagnóstico de estadística descriptiva y de datos faltantes. Cree una función que permita realizar el diagnóstico de forma flexible, la función debe retornar, media, desviación estándar, valores perdidos por descriptor, valor máximo y valor mínimo. Usted puede usar funciones internas de otras librerías. Cada uno de los estadísticos debe ser un argumento booleano en la función y solo cuando se indique True este se calculará. Los descriptores para los cuales se calcular´an estos descriptores también deben ser un argumento de la función."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute los datos perdidos con el método de su elección. Genere una función que reciba una lista de descriptores, el dataframe original y una lista con las estrategias de imputación de cada descriptor. La función debe retornar la nueva base de datos imputada. ¿Cómo cambió la distribución de los datos con la imputación realizada?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Modelos basados en árboles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Explore la documentación del modelo clasificador árbol de decisión link. Describa el aprendizaje de este modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Ajuste un árbol de decisión a los datos usados en las secciones anteriores y compare su rendimiento con respecto a los modelos naive Bayes y la regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Repita a y b pero con el clasificador random forest link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformación e Imputación de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar la base de datos (Gaia NaN.csv o metadato.csv ). Cree una función que permita cargar la base de datos bajo diferentes condiciones. Los argumentos de esta función deben ser: (i) un string con el nombre del directorio donde se encuetre la base de datos, (ii) una variable booleana que indique si se trabajará con una muestra o con la base de datos completa y (iii) un argumento que reciba las columnas con las que se pueda trabajar en una lista. Usted puede agregar nuevos argumentos que den mayor flexibilidad a la carga de datos. Recuerde verificar el tipo de variable reconocido por pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de modelos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
